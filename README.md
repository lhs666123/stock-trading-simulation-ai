# ğŸ“ˆ AI Stock Trading Simulation System

A multi-agent stock trading simulator with reinforcement learning capabilities, featuring three distinct AI trader types that evolve through iterative learning and experience sharing.

## âœ¨ Key Features

- **Three Intelligent Trader Types**: Emotional Investor vs Rational Fund Manager vs Insider Trader
- **Reinforcement Learning System**: AI agents learn from each trade outcome using Q-learning algorithms
- **Iterative Learning Enhancement**: Continuous strategy optimization through experience accumulation
- **Market Pattern Recognition**: Advanced technical analysis and trend detection
- **Meta-cognition System**: Agents understand their strengths/weaknesses and learn from mistakes
- **Multi-round Evolution**: Traders become smarter across simulation rounds

## ğŸ—ï¸ Project Structure

```
stock-trading-simulation/
â”œâ”€â”€ stock_simulation.py      # â­ Main simulation file (complete system)
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ README.md               # Documentation
â”œâ”€â”€ .env.example            # Environment variables template
â”œâ”€â”€ trader_*/               # Individual trader learning models
â”‚   â”œâ”€â”€ rl_model.json       # Reinforcement learning Q-table
â”‚   â”œâ”€â”€ strategy_optimizer.json  # Strategy performance data
â”‚   â””â”€â”€ pattern_recognizer.json  # Market pattern recognition data
â”œâ”€â”€ stock_database.json     # Generated stock market data
â””â”€â”€ output_files/           # Simulation results
    â”œâ”€â”€ trading_conversations_round_X.json
    â”œâ”€â”€ trading_experience_memory_round_X.json
    â””â”€â”€ trading_performance_round_X.json
```

## workflow
```mermaid
    graph TD
    A[ğŸš€ å¼€å§‹è‚¡ç¥¨äº¤æ˜“æ¨¡æ‹Ÿ] --> B[åˆå§‹åŒ–ç³»ç»Ÿ]
    
    B --> B1[ğŸ“Š ç”Ÿæˆè‚¡ç¥¨æ•°æ®]
    B --> B2[ğŸ¤– åˆ›å»ºæ™ºèƒ½ä½“]
    B --> B3[ğŸ’¾ åŠ è½½å­¦ä¹ æ¨¡å‹]
    
    B1 --> B11[ğŸ“ˆ ç”Ÿæˆ10åªè‚¡ç¥¨]
    B1 --> B12[ğŸ”„ ç”Ÿæˆ30å¤©æ•°æ®]
    B1 --> B13[ğŸ’¾ ä¿å­˜åˆ°JSON]
    
    B2 --> B21[ğŸ­ æƒ…ç»ªæŠ•èµ„è€…]
    B2 --> B22[ğŸ§  ç†æ€§åŸºé‡‘ç»ç†]
    B2 --> B23[ğŸ•µï¸ ä¿¡æ¯æ³„éœ²è€…]
    
    B3 --> B31[åŠ è½½Q-learningæ¨¡å‹]
    B3 --> B32[åŠ è½½ç­–ç•¥ä¼˜åŒ–å™¨]
    B3 --> B33[åŠ è½½æ¨¡å¼è¯†åˆ«å™¨]
    
    B21 --> C{æ¨¡æ‹Ÿè½®æ¬¡å¾ªç¯}
    B22 --> C{æ¨¡æ‹Ÿè½®æ¬¡å¾ªç¯}
    B23 --> C{æ¨¡æ‹Ÿè½®æ¬¡å¾ªç¯}
    
    C --> D[ğŸ¯ ç¬¬Nè½®æ¨¡æ‹Ÿ]
    D --> E[åˆå§‹åŒ–æœ¬è½®æ•°æ®]
    
    E --> F{å‘¨å¾ªç¯ 4å‘¨}
    
    F --> G[ğŸ“… ç¬¬Må‘¨å¼€å§‹]
    G --> H{æ—¥å¾ªç¯ 7.5å¤©}
    
    H --> I[ğŸŒ… ç¬¬Kå¤©äº¤æ˜“]
    
    I --> J[ğŸ“¢ å¸‚åœºè¯„è®º<br>æ¯éš”3å¤©]
    I --> K[ğŸ“° æ–°é—»ååº”<br>ç‰¹å®šæ—¥æœŸ]
    I --> L[ğŸ¤ äº¤æ˜“æ‰§è¡Œ]
    I --> M[ğŸ“Š ç»“æœåˆ†æ]
    
    L --> L1[ğŸ­ æƒ…ç»ªæŠ•èµ„è€…å†³ç­–]
    L --> L2[ğŸ§  ç†æ€§åŸºé‡‘ç»ç†å†³ç­–]
    L --> L3[ğŸ•µï¸ ä¿¡æ¯æ³„éœ²è€…å†³ç­–]
    
    L1 --> L11[åŸºäºæƒ…ç»ªäº¤æ˜“]
    L2 --> L21[åŸºäºæŠ€æœ¯åˆ†æ]
    L3 --> L31[åŸºäºå†…å¹•ä¿¡æ¯]
    
    M --> M1[è®¡ç®—æ”¶ç›Šç»“æœ]
    M --> M2[æ›´æ–°å¼ºåŒ–å­¦ä¹ ]
    M --> M3[è®°å½•ç»éªŒè®°å¿†]
    
    H --> N[ğŸ“ˆ è®¡ç®—å‘¨æ”¶ç›Šç‡]
    N --> O[ğŸ’¬ ç­–ç•¥è®¨è®ºä¼š]
    N --> P[ğŸ—£ï¸ ç»éªŒåˆ†äº«ä¼š]
    N --> Q[ğŸ“ äº’ç›¸å­¦ä¹ ]
    
    F --> R[ğŸ“Š è®°å½•å‘¨æ€§èƒ½]
    
    C --> S[ğŸŠ æœ€ç»ˆæ€»ç»“]
    
    S --> T[ğŸ“ˆ è®¡ç®—æ€»æ”¶ç›Š]
    S --> U[ğŸ† è¯„é€‰æœ€ä½³äº¤æ˜“è€…]
    S --> V[ğŸ“š è¯„é€‰å­¦ä¹ è¿›æ­¥å¥–]
    S --> W[ğŸ’¾ ä¿å­˜å­¦ä¹ æ¨¡å‹]
    
    W --> X[ä¿å­˜RLæ¨¡å‹]
    W --> Y[ä¿å­˜ç­–ç•¥ä¼˜åŒ–å™¨]
    W --> Z[ä¿å­˜æ¨¡å¼è¯†åˆ«å™¨]
    
    S --> AA[ğŸ“‹ ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶]
    
    AA --> AB[trading_conversations.json]
    AA --> AC[trading_experience_memory.json]
    AA --> AD[trading_performance.json]
    AA --> AE[cumulative_learning.json]
    
    C --> AF{æ˜¯å¦è¿˜æœ‰ä¸‹ä¸€è½®?}
    AF -->|æ˜¯| D
    AF -->|å¦| AG[ğŸ æ¨¡æ‹Ÿå®Œæˆ]
```
## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

Required packages:
- pandas >= 2.0.0
- numpy >= 1.24.0
- python-dotenv >= 1.0.0
- openai >= 1.0.0

### 2. Configure API Key

Create a `.env` file with your DeepSeek API key:

```bash
# .env file content
DEEPSEEK_API_KEY=your_deepseek_api_key_here
```

**Getting API Key**:
1. Visit [DeepSeek Platform](https://platform.deepseek.com/)
2. Register and login
3. Create a new API Key in the "API Keys" section
4. Copy the API Key into your `.env` file

### 3. Run the Simulation

**Basic single-round simulation (30 days)**:
```bash
python stock_simulation.py
```

**Multi-round simulation (3 rounds)**:
```bash
python stock_simulation.py --rounds 3
```

**Fast mode (reduced commentary)**:
```bash
python stock_simulation.py --fast
```

**Reset learning models (start fresh)**:
```bash
python stock_simulation.py --reset-learning
```

## ğŸ¤– AI Trader Types

### 1. ğŸ­ Emotional Investor
- **Trading Style**: Emotion-driven, herd mentality, impulsive decisions
- **Learning Focus**: Emotional resilience, mistake memory, panic control
- **Strategy**: Market sentiment and price volatility based trading
- **Personality Traits**: High emotional volatility, strong herd mentality, impulsive

### 2. ğŸ§  Rational Fund Manager
- **Trading Style**: Analytical, disciplined, technical analysis based
- **Learning Focus**: Trend model accuracy, pattern recognition, risk management
- **Strategy**: Fundamental and technical analysis based rational investing
- **Personality Traits**: High analytical skills, patience, discipline

### 3. ğŸ•µï¸ Insider Trader
- **Trading Style**: Information advantage, opportunistic, aggressive
- **Learning Focus**: Information reliability, timing accuracy, source validation
- **Strategy**: Insider information advantage based trading
- **Personality Traits**: Secretive, opportunistic, aggressive

## ğŸ”„ Simulation Flow

### Daily Trading Process
1. **Market Commentary**: Top-performing traders share market insights
2. **News Reaction**: Traders react to market news events
3. **Trading Decisions**: Each trader makes buy/sell decisions
4. **Trade Execution**: Transactions are executed at current prices
5. **Learning Phase**: Agents analyze outcomes and update strategies

### Weekly Learning Cycle
1. **Performance Review**: Calculate weekly returns and portfolio values
2. **Strategy Discussion**: Top traders discuss trading strategies
3. **Experience Sharing**: All traders share lessons learned
4. **Peer Learning**: Less experienced traders learn from top performers
5. **Strategy Integration**: Integrate successful strategies

## ğŸ§  Learning Mechanisms

### Reinforcement Learning System
- **Q-learning Algorithm**: State-action-reward based learning
- **Exploration-Exploitation Balance**: Dynamic adjustment of learning parameters
- **State Representation**: Stock, action, market condition, trader confidence
- **Reward System**: Profit-based reward scaling

### Strategy Optimization
- **Performance Tracking**: Record strategy success rates
- **Contextual Adaptation**: Adjust strategies based on market conditions
- **Strategy Variation**: Generate creative strategy modifications

### Pattern Recognition
- **Technical Analysis**: Price patterns, volatility, momentum
- **Historical Success Rates**: Track pattern prediction accuracy
- **Adaptive Advice**: Generate trading recommendations based on patterns

## ğŸ“Š Output and Results

### Generated Files
- **stock_database.json**: 30-day stock data for 10 major tech stocks
- **trading_conversations_round_X.json**: Complete conversation logs
- **trading_experience_memory_round_X.json**: Individual trader memories and learnings
- **trading_performance_round_X.json**: Performance metrics and returns
- **trader_*/**: Persistent learning models for each trader

### Performance Metrics
- **Weekly Returns**: Per-trader weekly performance
- **Total Returns**: Overall simulation performance
- **Learning Progress**: Individual learning progression (0-100%)
- **Portfolio Analysis**: Holdings, cash positions, portfolio values

## âš™ï¸ Configuration Options

### Command Line Arguments
```bash
--days DAYS         Simulation days (default: 30)
--weeks WEEKS       Simulation weeks (default: 4)
--rounds ROUNDS     Number of simulation rounds (default: 1)
--fast              Fast mode (reduced commentary)
--reset-learning    Reset learning models
```

### Simulation Parameters
- **Initial Capital**: $100,000 per trader
- **Trading Days**: 30 days (4 weeks of 7.5 trading days)
- **Stock Universe**: 10 major tech stocks (AAPL, GOOGL, MSFT, etc.)
- **Learning Rate**: 0.1 (RL system)
- **Discount Factor**: 0.95 (RL system)

## ğŸ“ˆ Example Output

```
================================================================================
                            ğŸ“… Week 1 Trading (Round 1)
================================================================================

--- Day 1 ---

ğŸ“¢ Day 1 Market Commentary

æƒ…ç»ªæŠ•èµ„è€… (å­¦ä¹ è¿›åº¦: 0.0%) å‘è¡¨å¸‚åœºè¯„è®º:
æƒ…ç»ªæŠ•èµ„è€…: ä½œä¸ºä¸€ä¸ªæƒ…ç»ªæŠ•èµ„è€…ï¼Œæˆ‘çœ‹åˆ°å¸‚åœºæ³¢åŠ¨å°±å…´å¥‹...

ğŸ’° Week 1 Returns:
   æƒ…ç»ªæŠ•èµ„è€…: å‘¨æ”¶ç›Š +1.23%, æ€»æ”¶ç›Š +1.23%, å­¦ä¹ è¿›åº¦ 5.2%
   ç†æ€§åŸºé‡‘ç»ç†: å‘¨æ”¶ç›Š +0.89%, æ€»æ”¶ç›Š +0.89%, å­¦ä¹ è¿›åº¦ 3.8%
   ä¿¡æ¯æ³„éœ²è€…: å‘¨æ”¶ç›Š +2.45%, æ€»æ”¶ç›Š +2.45%, å­¦ä¹ è¿›åº¦ 8.1%

================================================================================
                              âœ… Simulation Complete
================================================================================

ğŸ† Monthly Best Trader: ä¿¡æ¯æ³„éœ²è€… (ç»¼åˆå¾—åˆ†: 0.82)
ğŸ“š Most Learning Progress: æƒ…ç»ªæŠ•èµ„è€… (å­¦ä¹ è¿›åº¦: 35.6%)

âœ… All results saved to JSON files!
ğŸ’¾ Trader learning models saved for next round
```

## ğŸ”§ Customization

### Adding New Trader Types
1. Create new trader class inheriting from `BaseTrader`
2. Implement `make_trading_decisions` method
3. Define unique personality traits
4. Add to simulation initialization

### Modifying Market Parameters
- Edit `StockDataGenerator` class for different stock selection
- Adjust price generation parameters in `generate_stock_data`
- Modify `_generate_market_news` for custom news events

### Adjusting Learning Parameters
- Modify `ReinforcementLearningSystem` parameters
- Adjust `TradingStrategyOptimizer` adaptation rates
- Configure `MarketPatternRecognizer` thresholds

## ğŸ“ FAQ

### Q: API call failed, what should I do?
A: Check:
1. Correct API key in `.env` file
2. Network connectivity
3. DeepSeek API service status
4. Sufficient API credits

### Q: Simulation runs too slow?
A: Try:
1. Use `--fast` mode
2. Reduce simulation days (`--days 15`)
3. Reduce number of stocks in `StockDataGenerator`

### Q: How to interpret the learning progress percentage?
A: Learning progress (0-100%) indicates:
- 0-30%: Exploration phase, making basic trades
- 30-60%: Learning phase, improving strategies
- 60-90%: Optimization phase, refining approaches
- 90-100%: Mastery phase, consistent performance

### Q: Can I use different LLM APIs?
A: Yes! Modify the `AIClient` class:
```python
# Change to OpenAI
self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
self.model = "gpt-4"
```

## ğŸ§ª Testing

Verify the system:
```bash
# Check Python syntax
python -m py_compile stock_simulation.py

# Test imports
python -c "import pandas; import numpy; print('Dependencies OK')"

# Run quick test
python stock_simulation.py --fast --days 5
```

## ğŸ¤ Contributing

Issues and Pull Requests are welcome! Key areas for contribution:
- New trader types with unique strategies
- Additional technical indicators
- Enhanced learning algorithms
- Visualization tools for results

## ğŸ“„ License

MIT License

## ğŸ™ Acknowledgments

- [DeepSeek AI](https://www.deepseek.com/) for powerful LLM API
- [OpenAI Python SDK](https://github.com/openai/openai-python) for API client
- [Pandas](https://pandas.pydata.org/) and [NumPy](https://numpy.org/) for data processing

---

**ğŸ“ˆ Start your AI trading simulation journey! Watch intelligent agents evolve from novice traders to market masters through reinforcement learning and experience sharing.**